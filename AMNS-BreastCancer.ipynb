{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "74fdf274"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33597be1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/ufrn/AMNS/BASE/Breast_cancer.csv'\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA"
      ],
      "metadata": {
        "id": "cMdw3BoHyh6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class PCA:\n",
        "    def __init__(self, n_components):\n",
        "        self.n_components = n_components\n",
        "        self.components = None\n",
        "        self.mean = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        # 1. Centralizar os dados (subtrair a média)\n",
        "        self.mean = np.mean(X, axis=0)\n",
        "        X_centered = X - self.mean\n",
        "\n",
        "        # 2. Calcular a matriz de covariância\n",
        "        # rowvar=False indica que as colunas são as variáveis\n",
        "        cov_matrix = np.cov(X_centered, rowvar=False)\n",
        "\n",
        "        # 3. Calcular autovetores e autovalores\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "\n",
        "        # 4. Ordenar autovetores pelos autovalores em ordem decrescente\n",
        "        # Os autovetores são as colunas da matriz `eigenvectors`\n",
        "        eigenvectors = eigenvectors.T\n",
        "        idxs = np.argsort(eigenvalues)[::-1]\n",
        "        eigenvalues = eigenvalues[idxs]\n",
        "        eigenvectors = eigenvectors[idxs]\n",
        "\n",
        "        # 5. Armazenar os `n_components` primeiros autovetores\n",
        "        self.components = eigenvectors[0:self.n_components]\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Centralizar os dados usando a média do treino\n",
        "        X_centered = X - self.mean\n",
        "\n",
        "        # Projetar os dados nos componentes\n",
        "        # (n_samples, n_features) @ (n_features, n_components) -> (n_samples, n_components)\n",
        "        X_projected = np.dot(X_centered, self.components.T)\n",
        "\n",
        "        return X_projected\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZNp-BJKYzC_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")"
      ],
      "metadata": {
        "id": "sa8y9Km7yYdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimensões originais do Iris dataset:\", df.shape)"
      ],
      "metadata": {
        "id": "THBFq5LuzLLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "df_cleaned = df.replace('?', np.nan)\n",
        "\n",
        "for col in df_cleaned.columns:\n",
        "    if col != 'Class':\n",
        "        df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
        "\n",
        "# Drop rows with NaN values (resulting from '?' or other non-numeric entries)\n",
        "df_cleaned = df_cleaned.dropna()\n",
        "\n",
        "# Separate features from the target variable if 'Class' exists\n",
        "# For standardization, we typically only scale the feature columns\n",
        "X = df_cleaned.drop('Class', axis=1, errors='ignore') # 'errors=ignore' prevents error if 'Class' is not present\n",
        "\n",
        "# Padronizando as características\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# A média de cada coluna agora é próxima de 0\n",
        "print(\"Média após padronização:\", np.mean(df_scaled, axis=0))\n",
        "# O desvio padrão de cada coluna agora é próximo de 1\n",
        "print(\"Desvio padrão após padronização:\", np.std(df_scaled, axis=0))"
      ],
      "metadata": {
        "id": "-ut-j1QvzaGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciar e aplicar o PCA para reduzir de 4 para 2 dimensões\n",
        "pca_df = PCA(n_components=2)\n",
        "df_pca = pca_df.fit_transform(df_scaled)\n",
        "\n",
        "print(\"Dimensão dos dados após o PCA:\", df_pca.shape)"
      ],
      "metadata": {
        "id": "95ShP-CN0g4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "target_names = df_cleaned['Class'].unique()\n",
        "target_names.sort()\n",
        "\n",
        "colors = ['navy', 'darkorange']\n",
        "\n",
        "for color, target_name in zip(colors, target_names):\n",
        "    plt.scatter(df_pca[df_cleaned['Class'] == target_name, 0],\n",
        "                df_pca[df_cleaned['Class'] == target_name, 1],\n",
        "                color=color, alpha=.8, lw=2,\n",
        "                label=target_name)\n",
        "\n",
        "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
        "plt.title('PCA do Dataset')\n",
        "plt.xlabel('Primeiro Componente Principal (PC1)')\n",
        "plt.ylabel('Segundo Componente Principal (PC2)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pf0wG76N0zVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K_means"
      ],
      "metadata": {
        "id": "8PgeBqPLyekr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class KMeans:\n",
        "    def __init__(self, n_clusters=3, max_iter=100, random_state=42):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iter = max_iter\n",
        "        self.random_state = random_state\n",
        "        self.centroids = None\n",
        "        self.labels = None\n",
        "\n",
        "    def _initialize_centroids(self, X):\n",
        "        \"\"\"\n",
        "        Inicializa os centróides selecionando K pontos aleatórios do dataset.\n",
        "        \"\"\"\n",
        "        np.random.seed(self.random_state)\n",
        "        n_samples = X.shape[0]\n",
        "        random_indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
        "        # Corrected: Use .iloc for integer-location based indexing on DataFrame\n",
        "        self.centroids = X.iloc[random_indices].values\n",
        "\n",
        "    def _assign_clusters(self, X):\n",
        "        \"\"\"\n",
        "        Atribui cada ponto de dado ao centróide mais próximo.\n",
        "        \"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        distances = np.zeros((n_samples, self.n_clusters))\n",
        "\n",
        "        for i, centroid in enumerate(self.centroids):\n",
        "            distances[:, i] = np.sum((X - centroid)**2, axis=1)\n",
        "\n",
        "        self.labels = np.argmin(distances, axis=1)\n",
        "\n",
        "    def _update_centroids(self, X):\n",
        "        \"\"\"\n",
        "        Atualiza a posição de cada centróide com base na média dos pontos atribuídos a ele.\n",
        "        \"\"\"\n",
        "        new_centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
        "\n",
        "        for i in range(self.n_clusters):\n",
        "            cluster_points = X[self.labels == i]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centroids[i] = np.mean(cluster_points, axis=0)\n",
        "            else:\n",
        "                new_centroids[i] = self.centroids[i]\n",
        "\n",
        "        self.centroids = new_centroids\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Executa o algoritmo K-Means.\n",
        "        \"\"\"\n",
        "        self._initialize_centroids(X)\n",
        "\n",
        "        for _ in range(self.max_iter):\n",
        "            old_centroids = self.centroids.copy()\n",
        "            self._assign_clusters(X)\n",
        "            self._update_centroids(X)\n",
        "            if np.allclose(old_centroids, self.centroids):\n",
        "                break\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Atribui clusters para novos dados com base nos centróides aprendidos.\n",
        "        \"\"\"\n",
        "        distances = np.zeros((X.shape[0], self.n_clusters))\n",
        "        for i, centroid in enumerate(self.centroids):\n",
        "            distances[:, i] = np.sum((X - centroid)**2, axis=1)\n",
        "\n",
        "        return np.argmin(distances, axis=1)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NWynr34fxObG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "breast_df = pd.DataFrame(df_scaled, columns=X.columns)\n",
        "breast_df['species'] = df_cleaned['Class'].reset_index(drop=True)\n",
        "\n",
        "# Plotar o gráfico\n",
        "sns.pairplot(breast_df, hue='species', palette='viridis', diag_kind='kde')\n",
        "plt.suptitle('Pair Plot do Dataset Breast Cancer', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R8giMIXpL6qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_selected = X.iloc[:, [0, 1]]\n",
        "y_true = df_cleaned['Class']\n",
        "\n",
        "# Plotar o gráfico\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.scatter(X_selected.iloc[:, 0], X_selected.iloc[:, 1], c=y_true.astype('category').cat.codes, cmap='viridis', marker='o', s=50, edgecolor='k')\n",
        "plt.xlabel(X.columns[0])\n",
        "plt.ylabel(X.columns[1])\n",
        "plt.title('Dataset Breast Cancer - Features Selecionadas')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E2Lff-8bOKc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_range = range(1, 11)\n",
        "inertias = []\n",
        "\n",
        "for k in k_range:\n",
        "    model = KMeans(n_clusters=k, max_iter=150, random_state=42)\n",
        "    model.fit(X_selected)\n",
        "\n",
        "    current_inertia = 0.0\n",
        "    for i in range(k):\n",
        "        cluster_points = X_selected[model.labels == i]\n",
        "        if len(cluster_points) > 0:\n",
        "            current_inertia += np.sum(np.sum((cluster_points - model.centroids[i])**2, axis=1))\n",
        "\n",
        "    inertias.append(current_inertia)\n",
        "\n",
        "# Plotar o gráfico\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, inertias, 'bo-')\n",
        "plt.xlabel('Número de Clusters (K)')\n",
        "plt.ylabel('Inércia (WCSS)')\n",
        "plt.title('Método do Cotovelo para Encontrar o K Ótimo')\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lgwd5lNoQKdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escolha ideal de K seria 3 ou 4 (ou até mesmo 2), irei optar por 4 por ter mais."
      ],
      "metadata": {
        "id": "ykiBd9yKS4F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_breast = KMeans(n_clusters=4, max_iter=150, random_state=42)\n",
        "kmeans_breast.fit(X_selected)\n",
        "\n",
        "final_centroids_breast = kmeans_breast.centroids\n",
        "predicted_labels_breast = kmeans_breast.labels"
      ],
      "metadata": {
        "id": "bUl-3WbuSzbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "axes[0].scatter(X_selected.iloc[:, 0], X_selected.iloc[:, 1], c=predicted_labels_breast, s=50, cmap='viridis', edgecolor='k')\n",
        "axes[0].scatter(final_centroids_breast[:, 0], final_centroids_breast[:, 1], s=250, marker='*', c='red', edgecolor='black', label='Centróides')\n",
        "axes[0].set_title('Clusters Encontrados pelo K-Means (K=4)')\n",
        "axes[0].set_xlabel(X_selected.columns[0])\n",
        "axes[0].set_ylabel(X_selected.columns[1])\n",
        "axes[0].legend()\n",
        "axes[0].grid(True);\n",
        "\n",
        "scatter = axes[1].scatter(X_selected.iloc[:, 0], X_selected.iloc[:, 1], c=y_true.astype('category').cat.codes, s=50, cmap='viridis', edgecolor='k')\n",
        "axes[1].set_title('Classe Original - Breast Cancer Dataset')\n",
        "axes[1].set_ylabel(X_selected.columns[1])\n",
        "axes[1].legend(handles=scatter.legend_elements()[0], labels=target_names.tolist())\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.suptitle('Comparação: K-Means (K=4) vs. Rótulo Original (Breast Cancer Dataset)', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aSbBcoV5UKoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mode\n",
        "import numpy as np\n",
        "\n",
        "correct_predictions_breast = 0\n",
        "n_samples_breast = X_selected.shape[0]\n",
        "\n",
        "for i in range(kmeans_breast.n_clusters):\n",
        "    mask = (predicted_labels_breast == i)\n",
        "\n",
        "    if np.sum(mask) > 0:\n",
        "        dominant_label_breast = y_true[mask].mode()[0]\n",
        "\n",
        "        hits_breast = np.sum(y_true[mask] == dominant_label_breast)\n",
        "\n",
        "        correct_predictions_breast += hits_breast\n",
        "\n",
        "\n",
        "print(f\"Número de acertos: {correct_predictions_breast} de {n_samples_breast} pontos.\")\n",
        "print(f\"Taxa de acerto: {(correct_predictions_breast / n_samples_breast):.2%}\")"
      ],
      "metadata": {
        "id": "ldsybc16VEi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar que a taxa ficou acima do espera (70%), então o modelo foi bem treinado."
      ],
      "metadata": {
        "id": "p9BL4YwTVkGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hierarchical"
      ],
      "metadata": {
        "id": "QZTz-M2T_ZBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HierarchicalClustering:\n",
        "    def __init__(self, linkage='single'):\n",
        "        \"\"\"\n",
        "        Inicializa o algoritmo de clusterização hierárquica.\n",
        "\n",
        "        Parameters:\n",
        "        linkage: str, critério de ligação ('single', 'complete', 'average')\n",
        "        \"\"\"\n",
        "        self.linkage = linkage\n",
        "        self.merge_history = []\n",
        "        self.distances = []\n",
        "\n",
        "    def _calculate_distance_matrix(self, X):\n",
        "        \"\"\"\n",
        "        Calcula a matriz de distâncias entre todos os pares de pontos.\n",
        "        \"\"\"\n",
        "        n = len(X)\n",
        "        dist_matrix = np.zeros((n, n))\n",
        "\n",
        "        for i in range(n):\n",
        "            for j in range(i+1, n):\n",
        "                dist = np.linalg.norm(X[i] - X[j])\n",
        "                dist_matrix[i, j] = dist\n",
        "                dist_matrix[j, i] = dist\n",
        "\n",
        "        return dist_matrix\n",
        "\n",
        "    def _cluster_distance(self, cluster1, cluster2, X, dist_matrix):\n",
        "        \"\"\"\n",
        "        Calcula a distância entre dois clusters baseado no critério de ligação.\n",
        "        \"\"\"\n",
        "        if self.linkage == 'single':\n",
        "            # Distância mínima entre qualquer par de pontos dos clusters\n",
        "            min_dist = float('inf')\n",
        "            for i in cluster1:\n",
        "                for j in cluster2:\n",
        "                    if dist_matrix[i, j] < min_dist:\n",
        "                        min_dist = dist_matrix[i, j]\n",
        "            return min_dist\n",
        "\n",
        "        elif self.linkage == 'complete':\n",
        "            # Distância máxima entre qualquer par de pontos dos clusters\n",
        "            max_dist = 0\n",
        "            for i in cluster1:\n",
        "                for j in cluster2:\n",
        "                    if dist_matrix[i, j] > max_dist:\n",
        "                        max_dist = dist_matrix[i, j]\n",
        "            return max_dist\n",
        "\n",
        "        # elif self.linkage == 'average':\n",
        "        # Distância média entre todos os pares de pontos dos clusters\n",
        "        # ...\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Executa o algoritmo de clusterização hierárquica aglomerativa.\n",
        "        \"\"\"\n",
        "        n = len(X)\n",
        "\n",
        "        # Inicializar cada ponto como um cluster\n",
        "        clusters = [[i] for i in range(n)]\n",
        "\n",
        "        # Calcular matriz de distâncias inicial\n",
        "        dist_matrix = self._calculate_distance_matrix(X)\n",
        "\n",
        "        self.merge_history = []\n",
        "        self.distances = []\n",
        "\n",
        "        step = 0\n",
        "        print(f\"Passo inicial: {len(clusters)} clusters individuais\")\n",
        "        print(f\"Clusters: {clusters}\\n\")\n",
        "\n",
        "        # Continuar até que reste apenas um cluster\n",
        "        while len(clusters) > 1:\n",
        "            # Encontrar o par de clusters mais próximo\n",
        "            min_distance = float('inf')\n",
        "            merge_i, merge_j = -1, -1\n",
        "\n",
        "            for i in range(len(clusters)):\n",
        "                for j in range(i+1, len(clusters)):\n",
        "                    distance = self._cluster_distance(clusters[i], clusters[j], X, dist_matrix)\n",
        "                    if distance < min_distance:\n",
        "                        min_distance = distance\n",
        "                        merge_i, merge_j = i, j\n",
        "\n",
        "            # Combinar os clusters mais próximos\n",
        "            new_cluster = clusters[merge_i] + clusters[merge_j]\n",
        "\n",
        "            # Salvar informações da fusão\n",
        "            self.merge_history.append((clusters[merge_i].copy(), clusters[merge_j].copy()))\n",
        "            self.distances.append(min_distance)\n",
        "\n",
        "            step += 1\n",
        "            print(f\"Passo {step}: Combinar clusters {clusters[merge_i]} e {clusters[merge_j]}\")\n",
        "            print(f\"Distância: {min_distance:.3f}\")\n",
        "\n",
        "            # Remover os clusters antigos e adicionar o novo\n",
        "            clusters = [clusters[k] for k in range(len(clusters)) if k != merge_i and k != merge_j]\n",
        "            clusters.append(new_cluster)\n",
        "\n",
        "            print(f\"Clusters restantes: {clusters}\\n\")"
      ],
      "metadata": {
        "id": "ogi37gP1AXga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Breast Cancer:\")\n",
        "print(f\"Shape: {df_scaled.shape}\")\n",
        "print(f\"Features: {X.columns.tolist()}\") # Corrected: Use X.columns for feature names\n",
        "print(f\"Classes: {target_names.tolist()}\") # Corrected: Use target_names already defined\n",
        "\n",
        "# 2. Análise das features para seleção\n",
        "# Recreate breast_df using df_scaled (numpy array) with column names from X\n",
        "breast_df = pd.DataFrame(df_scaled, columns=X.columns)\n",
        "correlation_matrix = breast_df.corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Matriz de Correlação das Features do Dataset Breast Cancer')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DWgt5zC9C5nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjuw5j-O_YNp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "\n",
        "# Estilo para os gráficos\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "%matplotlib inline\n",
        "\n",
        "# Aplicar diferentes métodos de ligação\n",
        "methods = ['ward', 'complete', 'average', 'single']\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "\n",
        "for i, method in enumerate(methods):\n",
        "    # Calcular a matriz de ligação usando df_pca (dataset reduzido por PCA)\n",
        "    linkage_matrix = linkage(df_pca, method=method)\n",
        "\n",
        "    # Dendrograma\n",
        "    dendrogram(linkage_matrix, ax=axes[0, i], no_labels=True)\n",
        "    axes[0, i].set_title(f'Dendrograma - {method.capitalize()}')\n",
        "\n",
        "    # Obter 3 clusters\n",
        "    # Os clusters são obtidos do linkage_matrix gerado com df_pca\n",
        "    clusters = fcluster(linkage_matrix, 3, criterion='maxclust')\n",
        "\n",
        "    # Plotar os clusters, usando df_pca para visualização 2D e colorindo pelos clusters encontrados\n",
        "    scatter = axes[1, i].scatter(df_pca[:, 0], df_pca[:, 1], c=clusters, s=50, alpha=0.7, cmap='viridis')\n",
        "    axes[1, i].set_title(f'Clusters - {method.capitalize()}')\n",
        "    axes[1, i].set_xlabel('Primeiro Componente Principal (PC1)')\n",
        "    axes[1, i].set_ylabel('Segundo Componente Principal (PC2)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uNHxiO3B51V"
      },
      "source": [
        "from scipy.stats import mode\n",
        "import numpy as np\n",
        "\n",
        "def calculate_purity(y_true, y_pred):\n",
        "    correct_predictions = 0\n",
        "    n_samples = len(y_true)\n",
        "\n",
        "    for cluster_id in np.unique(y_pred):\n",
        "        mask = (y_pred == cluster_id)\n",
        "        if np.sum(mask) > 0:\n",
        "            dominant_label = mode(y_true[mask], keepdims=True)[0][0]\n",
        "            correct_predictions += np.sum(y_true[mask] == dominant_label)\n",
        "\n",
        "    return correct_predictions / n_samples\n",
        "\n",
        "print(\"Comparação dos métodos de ligação no dataset Breast Cancer:\")\n",
        "print(\"=\"*50)\n",
        "y_true_encoded = y_true.astype('category').cat.codes\n",
        "\n",
        "for method in methods:\n",
        "    linkage_matrix = linkage(df_pca, method=method)\n",
        "    clusters = fcluster(linkage_matrix, 2, criterion='maxclust')\n",
        "    purity = calculate_purity(y_true_encoded, clusters)\n",
        "    print(f\"{method.capitalize():12} Linkage: {purity:.1%} de acertos\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "linkage_matrix_ward = linkage(df_pca, method='ward')\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "dendrogram(linkage_matrix_ward, no_labels=True)\n",
        "plt.title('Dendrograma - Ward Linkage (Dataset Breast Cancer)') # Updated title\n",
        "plt.xlabel('Pontos de Dados')\n",
        "plt.ylabel('Distância')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nIFs0fPKGn-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters_to_test = [2, 3, 4]\n",
        "\n",
        "print(\"Análise do número ótimo de clusters (Ward Linkage no Dataset Breast Cancer):\")\n",
        "print(\"=\" * 69)\n",
        "\n",
        "fig, axes = plt.subplots(1, len(n_clusters_to_test), figsize=(20, 5))\n",
        "\n",
        "for i, n_clusters in enumerate(n_clusters_to_test):\n",
        "    clusters = fcluster(linkage_matrix_ward, n_clusters, criterion='maxclust')\n",
        "\n",
        "    scatter = axes[i].scatter(df_pca[:, 0], df_pca[:, 1], c=clusters, s=50, alpha=0.7, cmap='viridis')\n",
        "    axes[i].set_title(f'{n_clusters} Clusters (Ward)')\n",
        "    axes[i].set_xlabel('Primeiro Componente Principal (PC1)')\n",
        "    axes[i].set_ylabel('Segundo Componente Principal (PC2)')\n",
        "    axes[i].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TJMIjLEzG4d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import adjusted_rand_score\n",
        "\n",
        "for n_clusters in n_clusters_to_test:\n",
        "    # Obter clusters para o número específico de clusters\n",
        "    clusters = fcluster(linkage_matrix_ward, n_clusters, criterion='maxclust')\n",
        "\n",
        "    # Calcular Pureza\n",
        "    purity = calculate_purity(y_true_encoded, clusters)\n",
        "\n",
        "    # Calcular Adjusted Rand Index (ARI)\n",
        "    ari = adjusted_rand_score(y_true_encoded, clusters)\n",
        "\n",
        "    print(f\"Número de clusters: {n_clusters}\")\n",
        "    print(f\"  Pureza: {purity:.3f}\")\n",
        "    print(f\"  Adjusted Rand Index (ARI): {ari:.3f}\")"
      ],
      "metadata": {
        "id": "WBNN8z1jJlV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A melhor quantidade de Clusters é o 2.\n",
        "\n",
        "Ambas as purezas então próximos de 1. Entretanto, o ARI diminui sempre que o número de Clusters aumentam."
      ],
      "metadata": {
        "id": "ADkldE-5JyrI"
      }
    }
  ]
}